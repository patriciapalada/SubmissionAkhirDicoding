# -*- coding: utf-8 -*-
"""SUBMISSION_AKHIR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TnXLPvLlkRivNRjhs5V3t2RXwzPYBGJD

## **Submission Kelas "Belajar Pengembangan Machine Learning"**

### **Proyek Akhir : Image Classification Model Deployment**

Nama : Patricia Vhiola Palada

No. Registrasi : 0182180260-6

Email: patriciapalada88@gmail.com

***Summary:***
Submission ini menggunakan dataset yang berasal dari https://www.kaggle.com/crowww/a-large-scale-fish-dataset. Terdapat 9 class yang berisi jenis-jenis ikan.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from pathlib import Path
import os
import zipfile


import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

from sklearn.model_selection import train_test_split

import tensorflow as tf
from keras.models import load_model
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from keras.preprocessing import image
from keras.callbacks import EarlyStopping, History

from google.colab import files

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
os.environ['KAGGLE_CONFIG_DIR'] = '/content/gdrive/MyDrive/SUBMISSION'
# %cd /content/gdrive/MyDrive/SUBMISSION

!kaggle datasets download -d crowww/a-large-scale-fish-dataset

local_zip = '/content/gdrive/MyDrive/SUBMISSION/a-large-scale-fish-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

dataset_path = Path(r'/tmp/Fish_Dataset/Fish_Dataset')

file_path = list(dataset_path.glob(r'**/*.png'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_path))

file_path = pd.Series(file_path).astype(str)
labels = pd.Series(labels)

df = pd.concat([file_path, labels], axis=1)

df.columns = ['image', 'label']
df.head()

df.shape

fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})
for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(df.image[i]))
    ax.set_title(df.label[i])
    
plt.show()

df.label.value_counts()

df = df[df['label'].apply(lambda x: x[-2:] != 'GT')].reset_index(drop=True)
df.label.value_counts()

x_train, x_test = train_test_split(df, test_size=0.2,random_state=30)
x_train, x_val = train_test_split(x_train, test_size=0.2, random_state=30)

print("Shape of training data", x_train.shape)
print("Shape of test data", x_test.shape)
print("Shape of validation data", x_val.shape)

image_data_generator = ImageDataGenerator(rescale = 1./255,
    rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

train = image_data_generator.flow_from_dataframe(dataframe=x_train,
                                                 x_col='image', 
                                                 y_col='label', 
                                                 target_size=(200,200),
                                                 color_mode='rgb', 
                                                 class_mode='categorical',
                                                 shuffle=False)
test = image_data_generator.flow_from_dataframe(dataframe=x_test,
                                                x_col='image',
                                                y_col='label',
                                                target_size=(200,200), 
                                                color_mode='rgb', 
                                                class_mode='categorical', 
                                                shuffle=False)

val = image_data_generator.flow_from_dataframe(dataframe=x_val, 
                                               x_col='image', 
                                               y_col='label', 
                                               target_size=(200,200), 
                                               color_mode='rgb', 
                                               class_mode='categorical',
                                               shuffle=False)

class Callback(tf.keras.callbacks.Callback): 
    def on_epoch_end(self, epoch, logs={}): 
        if(logs.get('accuracy') > 0.92 and logs.get('val_accuracy') > 0.92):
            print("\nReached 92% accuracy") 
            self.model.stop_training = True 
 
callbacks = Callback()

input_shape = (200, 200, 3)
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape ),
    tf.keras.layers.MaxPool2D(pool_size = (2,2)),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size = (2,2)),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size = (2,2)),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D(pool_size = (2,2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(9, activation='softmax')
])

model.summary()

model.compile(optimizer="adam",
              loss='categorical_crossentropy', 
              metrics=["accuracy"])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = model.fit(train, 
#                     validation_data=val,
#                     epochs=50,
#                     callbacks=[callbacks])

pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()
plt.title("Accuracy")
plt.show()

pd.DataFrame(history.history)[['loss','val_loss']].plot()
plt.title("Loss")
plt.show()

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

